{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import traceback\n",
    "\n",
    "def setup_logging(log_file: str = \"app.log\"):\n",
    "    # Create a custom logger\n",
    "    logger = logging.getLogger(\"LinkExtractor\")\n",
    "    logger.setLevel(logging.INFO)  # Capture only INFO and above (INFO, WARNING, ERROR, CRITICAL)\n",
    "\n",
    "    # Prevent logger duplication\n",
    "    if not logger.hasHandlers():\n",
    "        # Create file handler to log to a file\n",
    "        file_handler = logging.FileHandler(log_file)\n",
    "        file_handler.setLevel(logging.INFO)  # File handler also captures only INFO and above\n",
    "\n",
    "        # Create log format with function name included\n",
    "        log_format = logging.Formatter('%(asctime)s - %(levelname)s - [%(funcName)s] - %(message)s')\n",
    "        file_handler.setFormatter(log_format)\n",
    "\n",
    "        # Add handler to the logger\n",
    "        logger.addHandler(file_handler)\n",
    "\n",
    "    return logger\n",
    "\n",
    "# Step 2: Set up logging to a file only, suppressing output in the notebook\n",
    "logger = setup_logging(log_file=\"notebook_logs.log\")\n",
    "\n",
    "# Step 3: Example usage\n",
    "logger.info(\"This is an INFO log message.\")\n",
    "logger.debug(\"This DEBUG message won't appear in INFO mode.\")\n",
    "logger.warning(\"This is a WARNING log message.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(text):\n",
    "    # Replace newline characters with an empty string\n",
    "    return text.replace('\\n', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Generator, Optional\n",
    "from lxml.html import HtmlElement, fromstring, tostring\n",
    "from lxml.html.clean import Cleaner\n",
    "import traceback\n",
    "from html2text import HTML2Text\n",
    "import requests\n",
    "import lxml\n",
    "from lxml.html import HtmlElement, tostring, fromstring\n",
    "def html_repr(self):\n",
    "    return lxml.html.tostring(self, encoding='unicode', pretty_print=True)\n",
    "\n",
    "HtmlElement.__repr__ = html_repr\n",
    "HtmlElement.__str__ = html_repr\n",
    "\n",
    "# Configure logging\n",
    "\"\"\"\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\"\"\"\n",
    "class WebScraper:\n",
    "    def __init__(self, url: str, base_xpath:str):\n",
    "        \"\"\"Initialize scraper with URL and extract body.\"\"\"\n",
    "        self.url = url\n",
    "        self.base_xpath = base_xpath\n",
    "        self.body = self._get_body()\n",
    "\n",
    "    def _get_body(self) -> Optional[HtmlElement]:\n",
    "        \"\"\"Fetch and clean HTML body from URL.\"\"\"\n",
    "        try:\n",
    "            logger.debug(f\"Fetching URL: {self.url}\")\n",
    "            #response = httpx.get(self.url)\n",
    "            response = requests.get(self.url, timeout=10)\n",
    "            html_tree = fromstring(response.text)\n",
    "\n",
    "            self.title = html_tree.xpath('//span[@class=\"mw-page-title-main\"]')[0].text_content()\n",
    "\n",
    "            body = html_tree.xpath('//body')[0]\n",
    "            assert isinstance(body, HtmlElement)\n",
    "            \n",
    "            logger.debug(\"Cleaning HTML body\")\n",
    "            cleaner = Cleaner(javascript=True, style=True)\n",
    "            cleaned_body = cleaner.clean_html(body)\n",
    "            \n",
    "            reconstructed_body = fromstring(''.join(\n",
    "                tostring(c, encoding='unicode') for c in cleaned_body\n",
    "            )).xpath(self.base_xpath)[0]\n",
    "\n",
    "            logger.info(f\"Successfully processed URL: {self.url}\")\n",
    "            return reconstructed_body\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing URL {self.url}: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            return None\n",
    "\n",
    "    def find_elements_by_xpaths(self, xpaths: List[str]) -> Generator[List[HtmlElement], None, None]:\n",
    "        \"\"\"Find elements in body using multiple XPaths.\"\"\"\n",
    "        if self.body is None:\n",
    "            logger.error(\"Body is None, cannot find elements\")\n",
    "            return\n",
    "        \n",
    "        for xpath in xpaths:\n",
    "            try:\n",
    "                logger.debug(f\"Searching for xpath: {xpath}\")\n",
    "                elements = self.body.xpath(xpath)\n",
    "                logger.info(f\"Found {len(elements)} elements for xpath: {xpath}\")\n",
    "                yield elements\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error finding elements with xpath {xpath}: {str(e)}\")\n",
    "                logger.error(traceback.format_exc())\n",
    "                yield []\n",
    "\n",
    "    def delete_elements_by_xpath(self, xpaths: List[str]) -> None:\n",
    "        \"\"\"Delete elements from body using multiple XPaths.\"\"\"\n",
    "        if self.body is None:\n",
    "            logger.error(\"Body is None, cannot delete elements\")\n",
    "            return\n",
    "        \n",
    "        for i, elements in enumerate(self.find_elements_by_xpaths(xpaths)):\n",
    "            logger.info(f\"{xpaths[i]} --> {len(elements)} elements found\")\n",
    "            for element in elements:\n",
    "                try:\n",
    "                    parent = element.getparent()\n",
    "                    if parent is not None:\n",
    "                        logger.debug(f\"Removing element: {remove_newlines(element.text_content())[:50]}...\")\n",
    "                        parent.remove(element)\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error removing element: {str(e)}\")\n",
    "                    logger.error(traceback.format_exc())\n",
    "\n",
    "    def get_following_siblings(self, element: HtmlElement) -> Generator[HtmlElement, None, None]:\n",
    "        \"\"\"Get all following siblings of an element.\"\"\"\n",
    "        try:\n",
    "            next_sibling = element.getnext()\n",
    "            while next_sibling is not None:\n",
    "                logger.debug(f\"Found sibling: {next_sibling.tag}\")\n",
    "                yield next_sibling\n",
    "                next_sibling = next_sibling.getnext()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error getting following siblings: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "\n",
    "    def delete_all_following_elements_by_xpath(self, xpath: str) -> int:\n",
    "        \"\"\"Delete all following sibling elements of the element found by xpath.\"\"\"\n",
    "        if self.body is None:\n",
    "            logger.error(\"Body is None, cannot delete following elements\")\n",
    "            return 0\n",
    "        \n",
    "        try:\n",
    "            element = self.body.xpath(xpath)[0]\n",
    "            logger.info(f\"Found target element: {element.text_content()[:50]}... following count: {len(list(self.get_following_siblings(element)))}\")\n",
    "            \n",
    "            sibling_following = list(self.get_following_siblings(element))\n",
    "            removed_count = 0\n",
    "\n",
    "            for sibling in sibling_following:\n",
    "                try:\n",
    "                    sibling.getparent().remove(sibling)\n",
    "                    removed_count += 1\n",
    "                    logger.debug(f\"Removed sibling: {sibling.text_content()[:20]}...\")\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Failed to remove sibling: {str(e)}\")\n",
    "                    logger.error(traceback.format_exc())\n",
    "            \n",
    "            logger.info(f\"Removed {removed_count} following elements\")\n",
    "            return removed_count\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in delete_all_following_elements_by_xpath: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            return 0\n",
    "      \n",
    "    def to_markdown(self, body_width: int = 500000) -> Optional[str]:\n",
    "        \"\"\"Convert the processed HTML body to markdown.\"\"\"\n",
    "        if self.body is None:\n",
    "            logger.error(\"Body is None, cannot convert to markdown\")\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            logger.debug(\"Converting HTML to markdown\")\n",
    "            h2t = HTML2Text(bodywidth=body_width)\n",
    "            h2t.ignore_links = True\n",
    "            h2t.mark_code = True\n",
    "            h2t.ignore_images = True\n",
    "            \n",
    "            html_string = tostring(self.body, encoding='unicode')\n",
    "            markdown_text = h2t.handle(html_string)\n",
    "            \n",
    "            logger.info(\"Successfully converted HTML to markdown\")\n",
    "            return f\"# {self.title} \\n{markdown_text}\"\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error converting to markdown: {str(e)}\")\n",
    "            logger.error(traceback.format_exc())\n",
    "            return None\n",
    "    def get_processed_body(self) -> Optional[HtmlElement]:\n",
    "        \"\"\"Return the processed body.\"\"\"\n",
    "        return self.body\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url='https://or.wikipedia.org/wiki/ପଦ୍ମ_ବିଭୂଷଣ'\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import  unquote\n",
    "url = \"https://or.wikipedia.org/wiki/%E0%AC%AA%E0%AC%A6%E0%AD%8D%E0%AC%AE_%E0%AC%AC%E0%AC%BF%E0%AC%AD%E0%AD%82%E0%AC%B7%E0%AC%A3\"\n",
    "url = unquote(url)\n",
    "print(f\"{url=}\")\n",
    "scraper = WebScraper(url, '//div[@id=\"mw-content-text\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xpaths_to_remove = [\n",
    "    '//div[@class=\"navbox\"]',\n",
    "    '//div'\n",
    "    '//a[@class=\"mw-jump-link\"]',\n",
    "    '//div[@class=\"vector-header-container\"]',\n",
    "    '//span[@class=\"plainlinks\"]',\n",
    "    '//nav',\n",
    "    '//div[@class=\"vector-page-toolbar\"]',\n",
    "    '//div[@class=\"title-shortlink-container\"]',\n",
    "    '//div[@id=\"p-lang-btn\"]',\n",
    "    '//div[@id=\"siteSub\"]',\n",
    "    '//div[@class=\"vector-page-toolbar\"]',\n",
    "    '//table[contains(@class, \"infobox\")]',\n",
    "    '//span[@class=\"mw-editsection\"]',\n",
    "    '//div[h2[@id=\"ଆଧାର\"]]',\n",
    "    '//div[@class=\"reflist\"]',\n",
    "    '//div[@class=\"printfooter\"]',\n",
    "    '//div[h2[@id=\"ବାହାର_ଆଧାର\"]]//following::ul',\n",
    "    '//div[h2[@id=\"ବାହାର_ଆଧାର\"]]',\n",
    "    '//div[@id=\"catlinks\"]',\n",
    "    '//div[@class=\"mw-footer-container\"]',\n",
    "    '//sup',\n",
    "]\n",
    "following_xpath = '//div[h2[@id=\"ଆଧାର\"]]'\n",
    "\n",
    "#scraper.delete_all_following_elements_by_xpath(following_xpath)\n",
    "#scraper.delete_elements_by_xpath(xpaths_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.delete_all_following_elements_by_xpath(following_xpath)\n",
    "scraper.delete_elements_by_xpath(xpaths_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_content = scraper.to_markdown()\n",
    "with open('temp.md', 'w') as file:\n",
    "    file.write(markdown_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
